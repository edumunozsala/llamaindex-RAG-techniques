{"cells":[{"cell_type":"markdown","metadata":{"id":"vPWR-aLboZ7l"},"source":["# Dense-X-Retrieval Pack\n","\n","This notebook walks through using the `DenseXRetrievalPack`, which parses documents into nodes, and then generates propositions from each node to assist with retreival.\n","\n","This follows the idea from the paper [Dense X Retrieval: What Retreival Granularity Should We Use?](https://arxiv.org/abs/2312.06648).\n","\n","From the paper, a proposition is described as:\n","\n","```\n","Propositions are defined as atomic expressions within text, each encapsulating a distinct factoid and presented in a concise, self-contained natural language format.\n","```\n","\n","We use the provided OpenAI prompt from their paper to generate propositions, which are then embedded and used to retrieve their parent node chunks."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13111,"status":"ok","timestamp":1702998785704,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-60},"id":"lvec4rdMojsw","outputId":"201bf92b-f245-4a0e-9084-8e0114dde159"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting python-dotenv\n","  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Collecting llama-index\n","  Downloading llama_index-0.9.16.post1-py3-none-any.whl (990 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.2/990.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-hub\n","  Downloading llama_hub-0.0.60-py3-none-any.whl (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.23)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n","Collecting beautifulsoup4<5.0.0,>=4.12.2 (from llama-index)\n","  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dataclasses-json (from llama-index)\n","  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n","Collecting deprecated>=1.2.9.3 (from llama-index)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n","Collecting httpx (from llama-index)\n","  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.8)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n","Collecting openai>=1.1.0 (from llama-index)\n","  Downloading openai-1.5.0-py3-none-any.whl (223 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n","Collecting tiktoken>=0.3.3 (from llama-index)\n","  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting types-protobuf<5.0.0.0,>=4.24.0.4 (from llama-index)\n","  Downloading types_protobuf-4.24.0.4-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\n","Collecting typing-inspect>=0.8.0 (from llama-index)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting html2text (from llama-hub)\n","  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from llama-hub) (5.9.5)\n","Collecting pyaml<24.0.0,>=23.9.7 (from llama-hub)\n","  Downloading pyaml-23.9.7-py3-none-any.whl (23 kB)\n","Collecting retrying (from llama-hub)\n","  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (4.0.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index) (2.5)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index) (1.14.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (4.66.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index) (1.7.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (1.10.13)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (1.3.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (2023.11.17)\n","Collecting httpcore==1.* (from httpx->llama-index)\n","  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (3.6)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml<24.0.0,>=23.9.7->llama-hub) (6.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.2)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index)\n","  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\n","Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->llama-hub) (1.16.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index) (1.2.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.2)\n","Installing collected packages: types-protobuf, retrying, python-dotenv, pyaml, mypy-extensions, marshmallow, html2text, h11, deprecated, beautifulsoup4, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index, llama-hub\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.11.2\n","    Uninstalling beautifulsoup4-4.11.2:\n","      Successfully uninstalled beautifulsoup4-4.11.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed beautifulsoup4-4.12.2 dataclasses-json-0.6.3 deprecated-1.2.14 h11-0.14.0 html2text-2020.1.16 httpcore-1.0.2 httpx-0.25.2 llama-hub-0.0.60 llama-index-0.9.16.post1 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.5.0 pyaml-23.9.7 python-dotenv-1.0.0 retrying-1.3.4 tiktoken-0.5.2 types-protobuf-4.24.0.4 typing-inspect-0.9.0\n"]}],"source":["!pip install python-dotenv llama-index llama-hub"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":523,"status":"ok","timestamp":1702999453169,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-60},"id":"VZpsdWbUoZ7r"},"outputs":[],"source":["import nest_asyncio\n","nest_asyncio.apply()"]},{"cell_type":"markdown","metadata":{"id":"gRWTBSnPoZ7t"},"source":["## Setup"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1702998896340,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-60},"id":"DIQrpGOroZ7t","outputId":"ff9e25b9-b437-4398-c0c3-792e841db23a"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from dotenv import load_dotenv\n","\n","# Load the enviroment variables\n","load_dotenv()"]},{"cell_type":"markdown","metadata":{},"source":["For this demo we use a simple PDFReader to read and extract the documents. You can use the following section to use a more advanced document loader and extract complete documents from the PDF file."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":13890,"status":"ok","timestamp":1702999194638,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-60},"id":"hr7bgdjJoZ7x"},"outputs":[],"source":["from pathlib import Path\n","from llama_index import download_loader\n","\n","PDFReader = download_loader(\"PDFReader\")\n","\n","loader = PDFReader()\n","documents = loader.load_data(file=Path('Attention is all you need.pdf'))"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vEqjQ70-oZ7v","outputId":"ebf08463-6829-4065-891a-478e4d9f1387"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\edumu\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\edumu\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","c:\\Users\\edumu\\Google Drive\\Projects\\llamaindex-RAG-techniques\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from llama_hub.file.unstructured import UnstructuredReader\n","\n","documents = UnstructuredReader().load_data(\"data/Attention is all you need.pdf\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1702999205202,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-60},"id":"5FvSqUOrqZIc","outputId":"03c8cb7c-66e0-438e-e313-7fb6da281ce5"},"outputs":[],"source":["documents"]},{"cell_type":"markdown","metadata":{"id":"OVwPz_JcoZ7y"},"source":["## Run the DenseXRetrievalPack\n","\n","The `DenseXRetrievalPack` creates both a retriver and query engine.\n","\n","First we download the package"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4781,"status":"ok","timestamp":1702999220772,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-60},"id":"y0hYTQZOoZ7z","outputId":"de3daf79-bc38-4fbd-c8fc-122fe3a2fc6a"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /tmp/llama_index...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["from llama_index.llama_pack import download_llama_pack\n","\n","DenseXRetrievalPack = download_llama_pack(\"DenseXRetrievalPack\", \"./dense_pack\")"]},{"cell_type":"markdown","metadata":{"id":"wa0p_pWpqplt"},"source":["Now, we create the retriever and the query engine from the `DenseXRetrieval` package using GPT 3.5-turbo as the LLM for the propositions extraction and for the query resolution."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["f15b8c42c3294842800f5775c43fdcd8","81610e08142a466d8453a6d043dbf175","879990fc968142db97247d659f045e65","eea2b9838ee64045a36b7b32ca37b7a9","58e2245268b64abab7aa94e2d0872904","9e6f3958d77346f7b3e092ea2a2f3fff","6d4408209ce74e49a679f226a20786d8","f7adcc7b1fad44dc91caeb5c3e622cd5","fe5eda700d5541019f7d030bfb6d2669","a221829c44af41e2b91b621ad4555098","d8a29d36ac84490eb25f420df0d80c9c"]},"executionInfo":{"elapsed":44583,"status":"ok","timestamp":1702999503227,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-60},"id":"BZ-7lENhoZ7z","outputId":"6e1f7bc0-ca56-4c0d-af43-612e19685e42"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 15/15 [00:41<00:00,  2.75s/it]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f15b8c42c3294842800f5775c43fdcd8","version_major":2,"version_minor":0},"text/plain":["Generating embeddings:   0%|          | 0/304 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from llama_index.llms import OpenAI\n","from llama_index.text_splitter import SentenceSplitter\n","\n","dense_pack = DenseXRetrievalPack(\n","  documents,\n","  proposition_llm=OpenAI(model=\"gpt-3.5-turbo\", max_tokens=750),\n","  query_llm=OpenAI(model=\"gpt-3.5-turbo\", max_tokens=256),\n","  text_splitter=SentenceSplitter(chunk_size=1024)\n",")\n","dense_query_engine = dense_pack.query_engine"]},{"cell_type":"markdown","metadata":{"id":"ucQ1R-vorlve"},"source":["Let's create a base query engine to compare the results"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":912,"status":"ok","timestamp":1702999685927,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-60},"id":"2b5jaHUGoZ70"},"outputs":[],"source":["from llama_index import VectorStoreIndex\n","\n","base_index = VectorStoreIndex.from_documents(documents)\n","base_query_engine = base_index.as_query_engine()"]},{"cell_type":"markdown","metadata":{"id":"PQ-a5H2IoZ70"},"source":["## Solve a Query"]},{"cell_type":"markdown","metadata":{"id":"jI76ispioZ71"},"source":["### How are transformers related to convolutional neural networks?"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3983,"status":"ok","timestamp":1702999609159,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-60},"id":"xi8SUUzZoZ71"},"outputs":[],"source":["response = dense_query_engine.query(\"How are transformers related to convolutional neural networks?\")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"elapsed":240,"status":"ok","timestamp":1702999626447,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-60},"id":"FRi-9FqgrxId","outputId":"795f1d14-a8b8-42ce-98ae-aa0ff65313c7"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Transformers are related to convolutional neural networks (CNNs) in that they both are used in sequence transduction models. However, transformers differ from CNNs in their architecture. While CNNs use convolutional layers to compute hidden representations in parallel for all input and output positions, transformers rely entirely on attention mechanisms to draw global dependencies between input and output. This allows transformers to be more parallelizable and requires less time to train compared to CNN-based models.'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["print(response.response)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4147,"status":"ok","timestamp":1702999719756,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-60},"id":"O1gn7HRxoZ72","outputId":"09dfc747-7e51-4a14-d44c-23fa7b271f93"},"outputs":[{"name":"stdout","output_type":"stream","text":["Transformers are related to convolutional neural networks (CNNs) in that they both can be used as building blocks in sequence transduction models. However, transformers differ from CNNs in their architecture. While CNNs use convolutional layers to compute hidden representations in parallel for all input and output positions, transformers rely entirely on an attention mechanism to draw global dependencies between input and output. This allows transformers to achieve more parallelization and reduce the number of operations required to relate signals from different positions.\n"]}],"source":["response = base_query_engine.query(\"How are transformers related to convolutional neural networks?\")\n","print(response.response)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"llama-index-4a-wkI5X-py3.11","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"58e2245268b64abab7aa94e2d0872904":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d4408209ce74e49a679f226a20786d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81610e08142a466d8453a6d043dbf175":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e6f3958d77346f7b3e092ea2a2f3fff","placeholder":"​","style":"IPY_MODEL_6d4408209ce74e49a679f226a20786d8","value":"Generating embeddings: 100%"}},"879990fc968142db97247d659f045e65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7adcc7b1fad44dc91caeb5c3e622cd5","max":304,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe5eda700d5541019f7d030bfb6d2669","value":304}},"9e6f3958d77346f7b3e092ea2a2f3fff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a221829c44af41e2b91b621ad4555098":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8a29d36ac84490eb25f420df0d80c9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eea2b9838ee64045a36b7b32ca37b7a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a221829c44af41e2b91b621ad4555098","placeholder":"​","style":"IPY_MODEL_d8a29d36ac84490eb25f420df0d80c9c","value":" 304/304 [00:02&lt;00:00, 144.62it/s]"}},"f15b8c42c3294842800f5775c43fdcd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81610e08142a466d8453a6d043dbf175","IPY_MODEL_879990fc968142db97247d659f045e65","IPY_MODEL_eea2b9838ee64045a36b7b32ca37b7a9"],"layout":"IPY_MODEL_58e2245268b64abab7aa94e2d0872904"}},"f7adcc7b1fad44dc91caeb5c3e622cd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe5eda700d5541019f7d030bfb6d2669":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
